{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carefull about python dependencies on this file. These are needed. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'couchdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3444269413ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# This is a python plugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcouchdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Connect to the database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'couchdb'"
     ]
    }
   ],
   "source": [
    "# Run a NoSQL database in a docker container ... study docker contrainer specially \"volumens\" to persist data to hard disk\n",
    "#docker run --name couchdb-01 -p 5984:5984 -v /home/couchdb-01/data:/opt/couchdb/data -v /home/couchdb-01/etc/local.d:/opt/couchdb/etc/local.d -e COUCHDB_USER=mqxadmin -e COUCHDB_PASSWORD=MQX-2020-couch -d couchdb:latest\n",
    "# This NoSQL database is extremely important to accelarate development since everything is document (json document). Everythin load on python, the web and mobile devices seemlessly\n",
    "\n",
    "# This is a python plugin\n",
    "import couchdb\n",
    "\n",
    "# Connect to the database\n",
    "secure_remote_server = couchdb.Server('https://XXXX:XXXXX@mqx-guest.theworkpc.com/mqx-couchdb')\n",
    "# Create new database\n",
    "#db = secure_remote_server.create('usdadata')\n",
    "# Connect to an existing database\n",
    "db = secure_remote_server['usdadata'] # existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from uuid import uuid4\n",
    "#doc_id = uuid4().hex\n",
    "#db[doc_id] =  { \\\n",
    "#    'type': 'report-listing', \\\n",
    "#    'name': 'LM_XB401', \\\n",
    "#    'description': 'National Daily Boneless Cow Beef & Beef Trimmings - Negotiated Sales - Afternoon (From 1:30 PM previous day to 1:30 PM current day)', \\\n",
    "#    'label': 'National Daily Boneless Cow Beef & Beef Trimmings',\n",
    "#    'category': 'beef',\n",
    "#    'frequency': \"daily\" \\\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from uuid import uuid4\n",
    "#doc_id = uuid4().hex\n",
    "#db[doc_id] =  { \\#{\n",
    "#  \"type\": \"report-listing\",\n",
    "#  \"name\": \"LM_XB403\",\n",
    "#  \"description\": \"National Daily Boxed Beef Cutout & Boxed Beef Cuts - Negotiated Sales - Afternoon (From 1:30 PM previous day to 1:30 PM current day)\",\n",
    "#  \"label\": \"National Daily Boxed Beef Cutout & Boxed Beef Cuts\",\n",
    "#  \"category\": \"beef\",\n",
    "#  \"frequency\": \"daily\"\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from uuid import uuid4\n",
    "#doc_id = uuid4().hex\n",
    "#db[doc_id] =  { \\\n",
    "#    'type': 'report-listing', \\\n",
    "#    'name': 'LM_XB405', \\\n",
    "#    'description': 'National Daily Cutter Cow Cutout and Boxed Cow Beef Cuts - Negotiated â€“ Afternoon(From 1:30 PM 7 days earlier to 1:30 PM current day)', \\\n",
    "#    'label': 'National Daily Cutter Cow Cutout and Boxed Cow Beef Cuts',\n",
    "#    'category': 'beef',\n",
    "#    'frequency': \"daily\" \\\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_id = \"_design/report-listing\" \n",
    "#db[doc_id] =  { \\\n",
    "#{\n",
    "#  \"views\": {\n",
    "#    \"report-listing-view\": {\n",
    "#      \"map\": \"function(doc) {\\n    if (doc.type == \\\"report-listing\\\") {\\n        emit(doc.name, [doc.category, doc.label, doc.frequency]);\\n    }\\n}\"\n",
    "#    },\n",
    "#    \"report-listing-categories\": {\n",
    "#      \"map\": \"function(doc) {\\n    if (doc.type == \\\"report-listing\\\") {\\n        emit(doc.category, doc.frequency);\\n    }\\n}\"\n",
    "#    },\n",
    "#    \"report-listing-labels\": {\n",
    "#      \"map\": \"function(doc) {\\n    if (doc.type == \\\"report-listing\\\") {\\n        emit(doc.label, doc.frequency);\\n    }\\n}\"\n",
    "#    }\n",
    "#  },\n",
    "#  \"language\": \"javascript\"\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USDA MPR/AMS Webservices https://mpr.ams.usda.gov/mpr/webServiceGuide.pdf\n",
    "# This function load data from USDA \n",
    "# Currently on LM_XB401, LM_XB403 and LM_XB405 are supported. \n",
    "# Couchdb Views defined earlier cleanup the data. No need to transform it, because Couchdb does it for you using views\n",
    "# NoSQL persisten storage is a very different paradigm from anything else.\n",
    "# TOODO connect Lucene Enterprise search to the document store\n",
    "\n",
    "import datetime\n",
    "import xmltodict\n",
    "import json\n",
    "import pprint\n",
    "from uuid import uuid4\n",
    "\n",
    "import re\n",
    "regex_newline = re.compile(r'[\\n]') \n",
    "regex_escapedquotes = re.compile(r'[\\\"]') \n",
    "\n",
    "\n",
    "# This function loads rerports types from USDA by identifier \n",
    "def loadReportListing( db, cycles, overwrite,name ):\n",
    "    today = datetime.date.today()\n",
    "    \n",
    "    #From today and \"cycles\" number of days backwards fetch documents and insert them on the document sotre.\n",
    "    \n",
    "    for row in db.view('_design/report-listing/_view/report-listing-view', key=name):\n",
    "        for i in list(range(cycles)):\n",
    "            if (row.value[2] == 'daily'):\n",
    "                delta_day = datetime.timedelta(days=i)\n",
    "                report_date = today - delta_day\n",
    "                print (report_date)\n",
    "                k = [name,report_date.strftime(\"%m/%d/%Y\")]\n",
    "                j = db.view('_design/fetched-reports/_view/fetched-reports-view', key=k)\n",
    "                # Do incert duplicate in the database, the document store can handle it but USDA can't. \n",
    "                #USDA will block your ip address if you download the same data plenty of time, get new data\n",
    "                if (len(j) > 0 and overwrite == False):\n",
    "                    print (\"bypassed\")\n",
    "                    continue\n",
    "                else:\n",
    "                    #Web Service URL struture is docuemented in the PDF mentioned earlier\n",
    "                    ws_query_url = 'https://mpr.datamart.ams.usda.gov/ws/report/v1/'+row.value[0]+'/'+row.key+'?filter={\"filters\":[{\"fieldName\":\"Report date\",\"operatorType\":\"EQUAL\",\"values\":[\"'+report_date.strftime(\"%m/%d/%Y\")+'\"]}]}'          \n",
    "                    print (ws_query_url)\n",
    "                    r = requests.get(ws_query_url)\n",
    "                    #\n",
    "                    # This is the beauty of docuemnt stores, get it, parse it, push it.\n",
    "                    #\n",
    "                    json_file = json.dumps(xmltodict.parse(r.content), skipkeys=False, ensure_ascii=False, check_circular=True, allow_nan=True, cls=None, indent=4, separators=None, default=None, sort_keys=True)\n",
    "                    json_file = regex_newline.sub('',json_file) \n",
    "                    json_file = regex_escapedquotes.sub('\"',json_file) \n",
    "                    doc_id = uuid4().hex\n",
    "                    doc = {\n",
    "                        '_id': doc_id, \n",
    "                        'type': 'report-fetch', \n",
    "                        'name': name, \n",
    "                        'category': 'beef',\n",
    "                        'frequency': \"daily\",\n",
    "                        'report_date': report_date.strftime(\"%m/%d/%Y\"),\n",
    "                        'data': json_file\n",
    "                    }\n",
    "                    db.save(doc)\n",
    "                    print (\"upserted\")\n",
    "                    #Done\n",
    "    return\n",
    "\n",
    "#These commands can be runned at anytime to load new data. or to populate a new database\n",
    "\n",
    "#loadReportListing(db, 365, False, \"LM_XB401\")\n",
    "#loadReportListing(db, 365, False, \"LM_XB403\")\n",
    "#loadReportListing(db, 365, False, \"LM_XB405\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### # This training model was inspired by the article:\n",
    "# https://www.thepythoncode.com/article/stock-price-prediction-in-python-using-tensorflow-2-and-keras\n",
    "# it uses date, open, high, low , close as feature to predict adj price\n",
    "# all the reports presented from USDA will need to export their data thorugh the view fetched-reports-data to fir this training model\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "#\n",
    "# This function prepares the data.\n",
    "# It is quite different from the original but it is simpler because the data comes cleans directly to it from CouchDB\n",
    "# It normalizes the data using the sklearn StandarScaler and separates the data in Training Sets and Test Sets for X and Y values\n",
    "# This is appication intends to predict price using features such as histircal data on date, open, high, low, average values\n",
    "# dataFrame is a pandas dataframe\n",
    "# n_steps are the amount of records used from historical recards for training\n",
    "# scale control if SKlearn StandardScaler will be enabled\n",
    "#\n",
    "\n",
    "def load_data(dataFrame, n_steps=70, scale=True, shuffle=True, lookup_step=1, test_size=0.2, feature_columns=['high', 'low', 'avg']):\n",
    "    result = {}\n",
    "    \n",
    "    # include a copy of the original data with the results\n",
    "    # function assumens you will be processing in batches\n",
    "    result['df'] = dataFrame.copy()\n",
    "    \n",
    "    # SAnity checks for features input columns\n",
    "    for col in feature_columns:\n",
    "        assert col in dataFrame.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    \n",
    "    # \n",
    "    # The shuffle the dataFrame \n",
    "    # For reproducable splits make sure to control the values of the following seeds\n",
    "    #        np.random.seed(XXXX)\n",
    "    #        tf.random.set_seed(XXXX)\n",
    "    #        random.seed(XXXX)\n",
    "    dataFrame.sample(frac = 1)\n",
    "\n",
    "    # Scale the dataFrame\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "            dataFrame[column] = scaler.fit_transform(np.expand_dims(dataFrame[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # Return a reference to the scaler with the returned ressults array\n",
    "\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    # This function makes a pocy of the desired column to be predicted \n",
    "    # and pushes it down as many cycles prediction would be required\n",
    "    dataFrame['future'] = dataFrame['avg'].shift(-lookup_step)\n",
    "    \n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(dataFrame[feature_columns].tail(lookup_step))\n",
    "    # After pushing down it store a reference where those are because sanitazing for NaN\n",
    "    \n",
    "    # drop NaNs; NumPy or anything done over the data can deal with NaNs on the Training or Tests \n",
    "    dataFrame.dropna(inplace=True)   \n",
    "\n",
    "    # Now it creates and array of paired sequences the size of n_steps\n",
    "    # Feature columns X column to be predicted\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    \n",
    "    for entry, target in zip(dataFrame[feature_columns].values, dataFrame['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # Since n_steps were use at every step the sequences should paired and sanitized for NumPy operations\n",
    "    \n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future prices not available in the dataset\n",
    "    last_sequence = list(sequences) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence)\n",
    "    # Refernce it on the return  result array\n",
    "    result['last_sequence'] = last_sequence\n",
    "    \n",
    "    # construct the X's and y's based on sequence data which was contructed using n_steps\n",
    "    # WARNING! be certain the dataFrame has more records thab n_steps!\n",
    "    # This code could be cleaned up but I have better things todo.\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X.reshape((X.shape[0], X.shape[2], X.shape[1]))\n",
    "    # python abuse, when I read this, I can imagine this thing blowing up and trying to understand why\n",
    "    # Again, WARNING the dataFrame has to have more rows that n_steps or this will blow\n",
    "\n",
    "    # split the dataset using Sklearn\n",
    "    # The shuffle command is passwd along \n",
    "    # For reproducable splits make sure to control the values of the folllwing seeds\n",
    "    #        np.random.seed(XXXX)\n",
    "    #        tf.random.set_seed(XXXX)\n",
    "    #        random.seed(XXXX)\n",
    "\n",
    "    result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, test_size=test_size, shuffle=shuffle)\n",
    "    return result\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LSTM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8ac0b90bbc3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Cell, Neural UNITS, Layers and dropout were parameterized by the original author\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n\u001b[0m\u001b[1;32m     11\u001b[0m                 loss=\"mean_squared_logarithmic_error\", optimizer=\"rmsprop\", bidirectional=False):\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LSTM' is not defined"
     ]
    }
   ],
   "source": [
    "### # This training model was inspired by the article:\n",
    "# https://www.thepythoncode.com/article/stock-price-prediction-in-python-using-tensorflow-2-and-keras\n",
    "# it uses date, open, high, low , close as feature to predict adj price\n",
    "# all the reports presented from USDA will need to export their data thorugh the view fetched-reports-data to fir this training model\n",
    "#\n",
    "# This is function creates the training model reference \n",
    "# Acivation RELU and metric Mean Squared Logarithmic Error are hard coded, they fit the data pretty well\n",
    "# Cell, Neural UNITS, Layers and dropout were parameterized by the original author\n",
    "\n",
    "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_squared_logarithmic_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"relu\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_squared_logarithmic_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### # This training model was inspired by the article:\n",
    "# https://www.thepythoncode.com/article/stock-price-prediction-in-python-using-tensorflow-2-and-keras\n",
    "# it uses date, open, high, low , close as feature to predict adj price\n",
    "# all the reports presented from USDA will need to export their data thorugh the view fetched-reports-data to fir this training model\n",
    "#\n",
    "# This function requires a functional training model reference; either trainned or loaded from diak\n",
    "# This function predicts the price. the column avg form the dataStrean is fixed... this is the column to be predicted\n",
    "\n",
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # retrieve the column scalers\n",
    "    column_scaler = data[\"column_scaler\"]\n",
    "    # reshape the last sequence\n",
    "    last_sequence = last_sequence.reshape((last_sequence.shape[1], last_sequence.shape[0]))\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    predicted_price = column_scaler[\"avg\"].inverse_transform(prediction)[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professor asked for five (5) partitions\n",
      "\n",
      "Chemical Lean, Fresh  81%\n",
      "\n",
      "Processing partition with seed = 314\n",
      "Plotted dataframe has 37 elements\n",
      "Train|Test: Numpy, Tensorflow2 and Python core will use 314 as seed for pseudo random generation\n",
      "Train|Test: Dataframe shuffled. 22 total sample from shuffled dataframe\n",
      "Train|Test: SKLearn splits 80/20% shuffled Train/Test partition\n",
      "Cross Validation: An unshuffle 22 size sample from original plotted dataframe\n",
      "Cross Valisdatio: SKLearn splits 80/20% unshuffled partition\n",
      "Tensorflow: Model predicts 1 day(s) into the future.\n",
      "Tensorflow: Long Short-Term memory (LSTM) network with 3 layers, 256 units, and a 0.4 dropout.\n",
      "Tensorflow: RNNs not bidirectional\n",
      "Tensorflow: Model trains with Mean Squared Logarithmic Erro Loss (MSLE)\n",
      "Tensorflow: Model trains with Adaptive extension to gradient descent (ADAP) as an optmizer\n",
      "Tensorflow: Model trains with 256 batch size and 100 epochs\n",
      "Tensorflow: Evaluates will Cross-Domain original unshuffled partition split with same parameter at it trained\n",
      "Mean Squared Logarithmic Error: 0.77224493\n",
      "Future price after 1 days is 183.33$\n",
      "\n",
      "Chemical Lean, Fresh  81%\n",
      "\n",
      "Processing partition with seed = 8989\n",
      "Plotted dataframe has 37 elements\n",
      "Train|Test: Numpy, Tensorflow2 and Python core will use 8989 as seed for pseudo random generation\n",
      "Train|Test: Dataframe shuffled. 22 total sample from shuffled dataframe\n",
      "Train|Test: SKLearn splits 80/20% shuffled Train/Test partition\n",
      "Cross Validation: An unshuffle 22 size sample from original plotted dataframe\n",
      "Cross Valisdatio: SKLearn splits 80/20% unshuffled partition\n",
      "Tensorflow: Model predicts 1 day(s) into the future.\n",
      "Tensorflow: Long Short-Term memory (LSTM) network with 3 layers, 256 units, and a 0.4 dropout.\n",
      "Tensorflow: RNNs not bidirectional\n",
      "Tensorflow: Model trains with Mean Squared Logarithmic Erro Loss (MSLE)\n",
      "Tensorflow: Model trains with Adaptive extension to gradient descent (ADAP) as an optmizer\n",
      "Tensorflow: Model trains with 256 batch size and 100 epochs\n",
      "Tensorflow: Evaluates will Cross-Domain original unshuffled partition split with same parameter at it trained\n",
      "Mean Squared Logarithmic Error: 0.0007663865\n",
      "Future price after 1 days is 184.10$\n",
      "\n",
      "Chemical Lean, Fresh  81%\n",
      "\n",
      "Processing partition with seed = 5487\n",
      "Plotted dataframe has 37 elements\n",
      "Train|Test: Numpy, Tensorflow2 and Python core will use 5487 as seed for pseudo random generation\n",
      "Train|Test: Dataframe shuffled. 22 total sample from shuffled dataframe\n",
      "Train|Test: SKLearn splits 80/20% shuffled Train/Test partition\n",
      "Cross Validation: An unshuffle 22 size sample from original plotted dataframe\n",
      "Cross Valisdatio: SKLearn splits 80/20% unshuffled partition\n",
      "Tensorflow: Model predicts 1 day(s) into the future.\n",
      "Tensorflow: Long Short-Term memory (LSTM) network with 3 layers, 256 units, and a 0.4 dropout.\n",
      "Tensorflow: RNNs not bidirectional\n",
      "Tensorflow: Model trains with Mean Squared Logarithmic Erro Loss (MSLE)\n",
      "Tensorflow: Model trains with Adaptive extension to gradient descent (ADAP) as an optmizer\n",
      "Tensorflow: Model trains with 256 batch size and 100 epochs\n"
     ]
    }
   ],
   "source": [
    "### # This training model was inspired by the article:\n",
    "# https://www.thepythoncode.com/article/stock-price-prediction-in-python-using-tensorflow-2-and-keras\n",
    "# it uses date, open, high, low , close as feature to predict adj price\n",
    "# all the reports presented from USDA will need to export their data thorugh the view fetched-reports-data to fir this training model\n",
    "#\n",
    "### This is function trains the models to be used by the mobile application\n",
    "# For each daily report by USDA it containes subreports, and these reports contain item description\n",
    "# Report Name => Subreport => Item description are the key to which Learning models are built and trainned\n",
    "# In addition to build and train the models, this function evaluate cross-validation\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "import datetime as dt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_finance import candlestick_ohlc\n",
    "import urllib.parse\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "# Utiliy function to create dictionary \n",
    "def multi_dict(K, type): \n",
    "    if K == 1: \n",
    "        return defaultdict(type) \n",
    "    else: \n",
    "        return defaultdict(lambda: multi_dict(K-1, type)) \n",
    "    \n",
    "\n",
    "\n",
    "# Fetch the reports names\n",
    "report_listings = db.view('_design/report-listing/_view/report-listing-view')\n",
    "\n",
    "# Fetch the subreports for every Report\n",
    "for report_listing in report_listings:\n",
    "#   print(report_listing)\n",
    "    name = report_listing['key']\n",
    "    # Fetch the subreports for every Report\n",
    "    report_listing_subreports = db.view('_design/fetched-reports/_view/fetched-reports-subreports', key=name)\n",
    "    subreportset = set()\n",
    "    for report_listing_subreport in report_listing_subreports:\n",
    "        subreportset.add(report_listing_subreport['value'])\n",
    "    # Remove view duplicates from subreports (data duplication was needed to clean up data presentation)\n",
    "    for subreport in subreportset:\n",
    "        subreportitemset = set()\n",
    "        # Fetch item data for each name, subreport pair\n",
    "        rawdata = db.view('_design/fetched-reports/_view/fetched-reports-data',key=[name,subreport])\n",
    "        for eachRow in rawdata:\n",
    "            subreportitemset.add(eachRow['value'][0])\n",
    "        #Remove duplicates for item descriptions\n",
    "\n",
    "        # For each item description create a visual plot\n",
    "        # Refernce array in for all this graphs\n",
    "        plot = {}\n",
    "        multi_dict(3, str) \n",
    "        \n",
    "        # For eveyy triple name, subreport, item a graph will be plotted, 5 models will be trained\n",
    "        # and 5 cross validations will be performced \n",
    "        \n",
    "        for subreportitem in subreportitemset:\n",
    "            rawdata = db.view('_design/fetched-reports/_view/fetched-reports-data', key=[name,subreport])\n",
    "            # mathplotlib needs special structure, fortunately it is the same structure for tensorflow\n",
    "            ohlc = []\n",
    "            # Numpy sanitazions\n",
    "            for eachRow in rawdata:\n",
    "                if (eachRow['value'][0] == subreportitem):\n",
    "                    date =  mdates.datestr2num(eachRow.value[1])\n",
    "                    inp = np.array([eachRow.value[2].replace(\",\", \"\") , eachRow.value[3].replace(\",\", \"\"), eachRow.value[4].replace(\",\", \"\"), eachRow.value[5].replace(\",\", \"\")])\n",
    "                    opt = inp.astype(np.float)\n",
    "                    append_me = date, opt[0], opt[1], opt[2], opt[3]\n",
    "                    ohlc.append(append_me)\n",
    "                    \n",
    "            # Plot graph it is useful to see the data \n",
    "            print()\n",
    "            plot[name,subreport,subreportitem] = plt.figure(figsize=(12,6)).add_subplot()\n",
    "            plot[name,subreport,subreportitem].grid(False)\n",
    "            candlestick_ohlc(plot[name,subreport,subreportitem], ohlc, width=5, colorup='g', colordown='r')\n",
    "            plot[name,subreport,subreportitem].set_axisbelow(True)\n",
    "            plot[name,subreport,subreportitem].set_title(name+' - '+subreport+' - '+subreportitem, color='white')\n",
    "            plot[name,subreport,subreportitem].set_facecolor('black')\n",
    "            plot[name,subreport,subreportitem].figure.set_facecolor('#121212')\n",
    "            plot[name,subreport,subreportitem].tick_params(axis='x', colors='white')\n",
    "            plot[name,subreport,subreportitem].tick_params(axis='y', colors='white')\n",
    "            plot[name,subreport,subreportitem].xaxis_date()\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            # The professor asked for five (5) partitions with its corresponding cross-valiation\n",
    "            # The partitions will be shuffled randomly with five (5) fixed seeds\n",
    "            # The original data will be used on its orginal order to create the validation partition\n",
    "            # set seed, so we can get the same results after rerunning several times\n",
    "            seeds = [314, 8989, 5487, 1432, 3333]\n",
    "            \n",
    "            \n",
    "            print(\"Professor asked for five (5) partitions\")\n",
    "            for seed in seeds:\n",
    "                \n",
    "                np.random.seed(seed)\n",
    "                tf.random.set_seed(seed)\n",
    "                random.seed(seed)\n",
    "            \n",
    "                subreportitem = subreportitem.replace(\"/\",\"-\")\n",
    "                print()\n",
    "                print(subreportitem)\n",
    "                print()\n",
    "                print(\"Processing partition with seed = \"+ str(seed))\n",
    "\n",
    "                # N_STEPS is the size of historical data used to train\n",
    "                # Make damn certain the grapg plotted dataStream has enough records\n",
    "                # Window size or the sequence length\n",
    "                \n",
    "                N_STEPS = min(math.floor(.6 * len (ohlc)), 256)\n",
    "                print (\"Plotted dataframe has \" + str(len (ohlc)) + \" elements\")\n",
    "            \n",
    "                # 20 points of data? forget about it\n",
    "                if (N_STEPS<20):\n",
    "                    print (\"Plotted dataframe does not have enough \" + str(N_STEPS) + \" elements for training. Skipping processing.\")\n",
    "                    continue\n",
    "                # test ratio size, 0.2 is 20%\n",
    "                # Partitions would be preferibly 20% TEST, 80% TRAIN\n",
    "                TEST_SIZE = 0.2\n",
    "                print (\"Train|Test: Numpy, Tensorflow2 and Python core will use \" + str(seed) + \" as seed for pseudo random generation\")\n",
    "                print (\"Train|Test: Dataframe shuffled. \" + str(N_STEPS) + \" total sample from shuffled dataframe\")\n",
    "                print (\"Train|Test: SKLearn splits 80/20% shuffled Train/Test partition\")\n",
    "                print (\"Cross Validation: An unshuffle \"  + str(N_STEPS) + \" size sample from original plotted dataframe\")\n",
    "                print (\"Cross Valisdatio: SKLearn splits 80/20% unshuffled partition\") \n",
    "                # Lookup step, 1 is the next day\n",
    "                # How far in future to predict?\n",
    "                LOOKUP_STEP = 1\n",
    "                print (\"Tensorflow: Model predicts \" + str(LOOKUP_STEP) + \" day(s) into the future.\" )\n",
    "\n",
    "                # features selected manually\n",
    "                FEATURE_COLUMNS = [\"avg\", \"high\", \"low\"]\n",
    "                # date now\n",
    "                date_now = time.strftime(\"%Y-%m-%d\")\n",
    "                ### model parameters tunnable\n",
    "                N_LAYERS = 3\n",
    "                # LSTM cell tensorflow cell\n",
    "                CELL = LSTM\n",
    "                # 256 LSTM neurons for net\n",
    "                UNITS = 256\n",
    "                # 40% dropout \n",
    "                DROPOUT = 0.4\n",
    "                # whether to use bidirectional RNNs\n",
    "                BIDIRECTIONAL = False\n",
    "                \n",
    "                print(\"Tensorflow: Long Short-Term memory (LSTM) network with \" + str(N_LAYERS) + \" layers, \" + str(UNITS) + \" units, and a \" + str(DROPOUT) + \" dropout.\")\n",
    "                if(BIDIRECTIONAL):\n",
    "                    print (\"Tensorflow: RNNs bidirectional\")\n",
    "                else:\n",
    "                    print (\"Tensorflow: RNNs not bidirectional\")\n",
    "                    \n",
    "                \n",
    "                ### training parameters\n",
    "                # Mean Squared Log Err\n",
    "                LOSS=\"msle\"\n",
    "                OPTIMIZER = \"adam\"\n",
    "                BATCH_SIZE = 256\n",
    "                EPOCHS = 100\n",
    "\n",
    "                \n",
    "                # model name to save, making it as unique as possible based on parameters\n",
    "                # These are the model file names\n",
    "                model_name = f\"{seed}-{name}-{subreport}-{subreportitem}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "                if BIDIRECTIONAL:\n",
    "                    model_name += \"-b\"\n",
    "    \n",
    "                # create these folders if they does not exist\n",
    "                # Some folder structure to store models, logs and original data sets\n",
    "                if not os.path.isdir(\"results\"):\n",
    "                    os.mkdir(\"results\")\n",
    "                if not os.path.isdir(\"logs\"):\n",
    "                    os.mkdir(\"logs\")\n",
    "                if not os.path.isdir(\"data\"):\n",
    "                    os.mkdir(\"data\")\n",
    "                \n",
    "\n",
    "                # Save CSVs of the original data sets\n",
    "                data_filename = os.path.join(\"data\", f\"{seed}-{name}-{subreport}-{subreportitem}.csv\")\n",
    "                \n",
    "\n",
    "                # load a new Pandas dataFrame from the graph plotted data\n",
    "                df = pd.DataFrame.from_records(ohlc, columns=['date', 'open', 'high', 'low', 'avg'])\n",
    "                \n",
    "\n",
    "                # load/prapare the data, this will create and return the shuffled Train/Test partition\n",
    "                # seed is used implicitely\n",
    "                data = load_data(df, N_STEPS, scale=True, shuffle=True, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\n",
    "\n",
    "                # save the dataframe\n",
    "                data[\"df\"].to_csv(data_filename)\n",
    "\n",
    "                # Train the model but\n",
    "                # Do not waste time in tensorflow recalculations\n",
    "                # if done then its done, if not then delete the file\n",
    "                if(not os.path.exists(os.path.join(\"results\", model_name) + \".h5\")):\n",
    "                    # construct the model refernce\n",
    "                    model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS, dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "                    # some tensorflow callbacks\n",
    "#                    checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=0)\n",
    "#                    tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "                    print(\"Tensorflow: Model trains with Mean Squared Logarithmic Erro Loss (MSLE)\")\n",
    "                    print(\"Tensorflow: Model trains with Adaptive extension to gradient descent (ADAP) as an optmizer\")\n",
    "                    print(\"Tensorflow: Model trains with \" + str(BATCH_SIZE) + \" batch size and \" + str(EPOCHS) + \" epochs\")     \n",
    "                    history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "#                        callbacks=[checkpointer, tensorboard],\n",
    "                        verbose=0)\n",
    "                    model.save(os.path.join(\"results\", model_name) + \".h5\")\n",
    "                else:\n",
    "                    print(\"Tensorflow: Loading pre-trained model from disk\")          \n",
    "\n",
    "            \n",
    "                # load/prapare the data, this will create and return Train/Test partition\n",
    "                # from the original plotted undisturbed data\n",
    "                # It is a control partition for cross-validation\n",
    "                df = pd.DataFrame.from_records(ohlc, columns=['date', 'open', 'high', 'low', 'avg'])\n",
    "                # Notice shuffle = False\n",
    "                data = load_data(df, N_STEPS, scale=True, shuffle=False, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,feature_columns=FEATURE_COLUMNS)\n",
    "                # construct the model again\n",
    "                model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "                # Load from disk\n",
    "                model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "                model.load_weights(model_path)\n",
    "            \n",
    "            \n",
    "                # Evaluate the model against Cross-Validation\n",
    "                print(\"Tensorflow: Evaluates will Cross-Domain original unshuffled partition split with same parameter at it trained\")          \n",
    "                eval_results = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "                # calculate terror (inverse scaling)?\n",
    "                # Not necessary?? because only percentages are considered by MSLE\n",
    "#                error = data[\"column_scaler\"][\"avg\"].inverse_transform([[eval_results[1]]])[0][0]\n",
    "#                error = eval_results[0]\n",
    "#                print(\"Mean Squared Logarithmic Error:\", error)\n",
    "                error = eval_results[1]\n",
    "                print(\"Mean Squared Logarithmic Error:\", error)\n",
    "            \n",
    "                # predict the future price\n",
    "                future_price = predict(model, data)\n",
    "                print(f\"Future price after {LOOKUP_STEP} days is ${future_price:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
